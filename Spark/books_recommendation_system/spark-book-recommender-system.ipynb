{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark import SparkConf,SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('file:///home/hadoop/workspaces/books_recommendation_system/datasets', 'BX-CSV-Dump')\n",
    "ratings_file_path = os.path.join(dataset_path, 'BX-Book-Ratings.csv')\n",
    "ratings_raw_RDD = sc.textFile(ratings_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_raw_data_header = ratings_raw_RDD.take(1)[0]\n",
    "ratings_RDD = ratings_raw_RDD.filter(lambda line : line != ratings_raw_data_header)\\\n",
    ".map(lambda line : line.split(';'))\\\n",
    ".map(lambda tokens : (int(tokens[0][1:-1]),abs(hash(tokens[1][1:-1])) % (10 ** 8),int(tokens[2][1:-1]))).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造训练集，测试集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,train,validate = ratings_RDD.randomSplit(weights = [0.3, 0.6, 0.1], seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(278854, 89577233, 7), (278851, 82832139, 0), (278851, 76278149, 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.map(lambda token : (token[0],token[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型\n",
    "## （1）参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12, 16, 20]\n",
    "errors = [0, 0, 0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （2）模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 9.779722167495578\n",
      "For rank 8 the RMSE is 1.9311406385604153\n",
      "For rank 12 the RMSE is 4.978624280268749\n",
      "For rank 16 the RMSE is 4.242691962481146\n",
      "For rank 20 the RMSE is 2.961898227522224\n"
     ]
    }
   ],
   "source": [
    "for rank in ranks:\n",
    "    model = ALS.train(train,rank,seed = seed,iterations = iterations, lambda_ = regularization_parameter)\n",
    "    predictions = model.predictAll(test).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validate.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was trained with rank 8\n"
     ]
    }
   ],
   "source": [
    "print('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((98391, 16891830), (9.0, 6.038101772477776))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((19378, 60135476), 4.464581323923139)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
