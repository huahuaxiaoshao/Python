{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv('titanic_train.csv')\n",
    "titanic.head()\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(titanic['Sex'].unique())\n",
    "#0:表示男，1表示女\n",
    "titanic.loc[titanic['Sex'] == 'male','Sex'] = 0\n",
    "titanic.loc[titanic['Sex'] == 'female','Sex'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print(titanic['Embarked'].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用线性回归方法\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "#预测所用到的特征\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "#初始化线性回归函数\n",
    "lg = LinearRegression()\n",
    "#初始化K折交叉验证函数\n",
    "kf = KFold(n_splits=3,shuffle=False)\n",
    "predictions = []\n",
    "for train,test in kf.split(titanic):\n",
    "    train_predictors = titanic[predictors].loc[train,:]\n",
    "    train_target = titanic['Survived'].loc[train]\n",
    "    lg.fit(train_predictors,train_target)\n",
    "    test_predictions = lg.predict(titanic[predictors].loc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3838383838383838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.concatenate(predictions,axis = 0)\n",
    "# print(predictions.shape)\n",
    "#匹配输出结果，1表示生存，0表示死亡\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 1\n",
    "accuracy = sum(predictions [predictions== titanic['Survived']]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878787878787877\n"
     ]
    }
   ],
   "source": [
    "#使用逻辑回归方法\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#初始化逻辑回归函数\n",
    "lr = LogisticRegression(random_state=1,solver='liblinear')\n",
    "#应用交叉验证并计算精确分数\n",
    "scores = cross_val_score(lr,titanic[predictors],titanic['Survived'],cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    }
   ],
   "source": [
    "#使用随机森林方法\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "# n_estimators:数的个数\n",
    "# min_samples_split:如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "# min_samples_leaf:这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝，如果样本量不大，不需要管这个值，大些如10W可是尝试下5\n",
    "rfc = RandomForestClassifier(random_state=1,n_estimators=10,min_samples_split=2,min_samples_leaf=1)\n",
    "# 初始化K折交叉验证函数\n",
    "kf = KFold(n_splits=3,shuffle=False)\n",
    "scores = cross_val_score(rfc,titanic[predictors],titanic['Survived'],cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "# 调整参数之后的随机森林\n",
    "rfc = RandomForestClassifier(random_state=1,n_estimators=100,min_samples_split=4,min_samples_leaf=2)\n",
    "# 初始化K折交叉验证函数\n",
    "kf = KFold(n_splits=3,shuffle=False)\n",
    "scores = cross_val_score(rfc,titanic[predictors],titanic['Survived'],cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成一个家庭人数列\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "# 生成一个姓名长度series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Col           2\n",
      "Major         2\n",
      "Capt          1\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Mme           1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Sir           1\n",
      "Countess      1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_title(name):\n",
    "    # 使用正则表达式搜索标题。标题总是由大写字母和小写字母组成，以句号结尾。\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.',name)\n",
    "    # 如果标题存在，提取并返回它.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return ''\n",
    "# 得到所有的名字的简称（title）\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "# 把每个title映射成整数，一些title是比较稀少的，所以被压缩成与其他标题相同的编码。\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "print(pd.value_counts(titles))\n",
    "# 添加一个新的列\n",
    "titanic['Title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 特征重要性分析\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "# f_classif为方差分析，计算f值，利用f值这个检验统计量，可以判断假设H0是否成立：f值越大，大到一定程度时，就有理由拒绝零假设，认为不同总体下的均值存在显著差异。\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "# 特征选择\n",
    "selector = SelectKBest(f_classif,k=5)\n",
    "selector.fit(titanic[predictors],titanic['Survived'])\n",
    "\n",
    "# 得到每一维特征的p值，把p值转化成分数\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "# 画出分数，观察特征的分数\n",
    "plt.bar(range(len(predictors)),scores)\n",
    "plt.xticks(range(len(predictors)),predictors,rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8170594837261503\n"
     ]
    }
   ],
   "source": [
    "# 根据上一幅图找出前四个最好的特征\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=1,n_estimators=50,min_samples_split=8,min_samples_leaf=4)\n",
    "scores = cross_val_score(rfc,titanic[predictors],titanic['Survived'],cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27946127946127947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1,n_estimators=25,max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]],\n",
    "    [LogisticRegression(random_state=1,solver='liblinear'), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "# 初始化交叉熵\n",
    "kf = KFold(n_splits=3,shuffle=False)\n",
    "predictions = []\n",
    "for train,test in kf.split(titanic):\n",
    "    train_target = titanic['Survived'].loc[train]\n",
    "    full_test_predictions = []\n",
    "    # 使用每个算法进行预测\n",
    "    for alg,predictors in algorithms:\n",
    "        alg.fit(titanic[predictors].loc[train,:],train_target)\n",
    "        # 在测试集上进行预测\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].loc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "    \n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# 把每个title映射成整数，一些title是比较稀少的，所以被压缩成与其他标题相同的编码。\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# 得到title的组数\n",
    "print(pd.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# 添加一个新的家庭大小列\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developenvironment\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.11682905, 0.47835541, 0.12614812, 0.13098152, 0.52105865,\n",
       "       0.14352087, 0.64085318, 0.18003148, 0.67801347, 0.12111116,\n",
       "       0.12105176, 0.20902103, 0.91068382, 0.10891264, 0.89142097,\n",
       "       0.87713471, 0.16349847, 0.13907786, 0.54103225, 0.55660983,\n",
       "       0.22420864, 0.53720786, 0.90572221, 0.38890591, 0.88384766,\n",
       "       0.10357312, 0.90909442, 0.13746448, 0.31046235, 0.12665715,\n",
       "       0.1166376 , 0.18274852, 0.55220981, 0.49648565, 0.42415294,\n",
       "       0.14191047, 0.50973625, 0.524522  , 0.13270502, 0.2836669 ,\n",
       "       0.11145277, 0.46618798, 0.09996496, 0.83420609, 0.89959114,\n",
       "       0.14983412, 0.31593403, 0.13789616, 0.89104178, 0.54189549,\n",
       "       0.35666363, 0.17718126, 0.83071945, 0.8799554 , 0.17559061,\n",
       "       0.13741805, 0.10667274, 0.12343845, 0.12099732, 0.91285174,\n",
       "       0.13099156, 0.15341939, 0.12993963, 0.66573198, 0.66343871,\n",
       "       0.87272599, 0.67238706, 0.28826487, 0.35236563, 0.85565528,\n",
       "       0.66224131, 0.12701988, 0.55390051, 0.36740453, 0.91110317,\n",
       "       0.41201932, 0.13014   , 0.83671261, 0.15614405, 0.66224131,\n",
       "       0.68129213, 0.20605729, 0.20382607, 0.12105176, 0.18486623,\n",
       "       0.13130208, 0.65680528, 0.53029851, 0.65489619, 0.79881216,\n",
       "       0.53764538, 0.12104024, 0.89137249, 0.13014   , 0.28406238,\n",
       "       0.12345362, 0.86792465, 0.14666332, 0.58599453, 0.12260776,\n",
       "       0.9043346 , 0.14730812, 0.13789616, 0.12262429, 0.62257485,\n",
       "       0.1315587 , 0.14607748, 0.13789616, 0.13020331, 0.17473028,\n",
       "       0.14286381, 0.65490305, 0.89528112, 0.67146752, 0.88346024,\n",
       "       0.13992075, 0.11805058, 0.69612517, 0.36668937, 0.86241692,\n",
       "       0.8764929 , 0.12609321, 0.9027637 , 0.12099022, 0.13789616,\n",
       "       0.56971929, 0.12608177, 0.63733734, 0.13339986, 0.13340569,\n",
       "       0.12723632, 0.51609589, 0.23921864, 0.10791691, 0.09896732,\n",
       "       0.12431119, 0.13346489, 0.16214091, 0.52029423, 0.12232635,\n",
       "       0.20712064, 0.90529653, 0.19747943, 0.16153709, 0.42927579,\n",
       "       0.10487174, 0.33642489, 0.1351841 , 0.46618798, 0.34478747,\n",
       "       0.91431378, 0.13214993, 0.10690994, 0.48983627, 0.11274825,\n",
       "       0.12427863, 0.91070165, 0.57991621, 0.42927579, 0.51274036,\n",
       "       0.65489227, 0.57884522, 0.82113375, 0.12096643, 0.28979591,\n",
       "       0.58587099, 0.30130458, 0.14606803, 0.90250408, 0.52257368,\n",
       "       0.12101879, 0.13299492, 0.12418531, 0.13207481, 0.13196549,\n",
       "       0.87293581, 0.87633413, 0.29670316, 0.83389516, 0.85558668,\n",
       "       0.15614405, 0.33352245, 0.90219082, 0.13789616, 0.91718924,\n",
       "       0.13602993, 0.85482384, 0.12241399, 0.14217314, 0.13560677,\n",
       "       0.13488024, 0.25547174, 0.49950987, 0.12729484, 0.71980834,\n",
       "       0.10795464, 0.85516524, 0.58990442, 0.16645661, 0.53980342,\n",
       "       0.64867959, 0.66329189, 0.60981586, 0.87333315, 0.1632263 ,\n",
       "       0.25696639, 0.63083508, 0.16482583, 0.88984704, 0.12346403,\n",
       "       0.12849648, 0.12097119, 0.24675036, 0.80199969, 0.41248331,\n",
       "       0.29768137, 0.65492652, 0.2186035 , 0.90027413, 0.13014   ,\n",
       "       0.81370011, 0.13611138, 0.84275389, 0.12700823, 0.87789278,\n",
       "       0.59807982, 0.12518083, 0.65489619, 0.11487488, 0.14413101,\n",
       "       0.25075172, 0.89266284, 0.11622679, 0.13791324, 0.34224635,\n",
       "       0.12796769, 0.1936585 , 0.14018896, 0.80948184, 0.89790831,\n",
       "       0.87598956, 0.82598157, 0.33036565, 0.12105097, 0.33258152,\n",
       "       0.28710736, 0.87902947, 0.16058981, 0.86241692, 0.59133082,\n",
       "       0.74586496, 0.15434322, 0.39647448, 0.13354264, 0.12701859,\n",
       "       0.12101879, 0.13789616, 0.13014   , 0.83005783, 0.12700581,\n",
       "       0.1089495 , 0.12701504, 0.85003755, 0.64929877, 0.16619529,\n",
       "       0.12105176, 0.21821002, 0.12101879, 0.50973625, 0.14016477,\n",
       "       0.34495854, 0.13789616, 0.91564003, 0.63328249, 0.13207434,\n",
       "       0.85713528, 0.15861627, 0.12500109, 0.14267169, 0.16811846,\n",
       "       0.52045065, 0.66231859, 0.65489619, 0.64136781, 0.71198855,\n",
       "       0.1060108 , 0.12099022, 0.36278086, 0.13207481, 0.13014   ,\n",
       "       0.3330445 , 0.59319576, 0.13207481, 0.50584342, 0.12081671,\n",
       "       0.1226365 , 0.7790318 , 0.12665715, 0.33024477, 0.12028971,\n",
       "       0.11813952, 0.17547878, 0.12169403, 0.1334714 , 0.65489619,\n",
       "       0.82133601, 0.33497542, 0.67696015, 0.209165  , 0.42575089,\n",
       "       0.13912865, 0.13799524, 0.12102117, 0.61904726, 0.90111958,\n",
       "       0.67393642, 0.23919459, 0.17328799, 0.12182849, 0.18522948,\n",
       "       0.12262429, 0.13491473, 0.16214091, 0.45541294, 0.90601339,\n",
       "       0.12509879, 0.86563778, 0.34598569, 0.14469713, 0.17034211,\n",
       "       0.8214761 , 0.32823558, 0.13207434, 0.64322905, 0.12183257,\n",
       "       0.25111388, 0.15333416, 0.09370084, 0.20950798, 0.35411795,\n",
       "       0.17507142, 0.11812295, 0.1469565 , 0.91556472, 0.33657646,\n",
       "       0.61836794, 0.16214091, 0.62462664, 0.16542882, 0.85157874,\n",
       "       0.89603821, 0.1632263 , 0.24472814, 0.16066606, 0.7003103 ,\n",
       "       0.15642441, 0.85672633, 0.12105018, 0.13789616, 0.57255223,\n",
       "       0.10418824, 0.87672473, 0.86918832, 0.13098152, 0.91914163,\n",
       "       0.15715004, 0.13130246, 0.53322125, 0.89562963, 0.17356044,\n",
       "       0.15319838, 0.90891502, 0.16307923, 0.13130565, 0.87654852,\n",
       "       0.90969192, 0.48853349, 0.17002319, 0.19866953, 0.13510976,\n",
       "       0.13789616, 0.14010259, 0.54133841, 0.59499235, 0.15905627,\n",
       "       0.83276877, 0.12430271, 0.12019379, 0.14606632, 0.18789785,\n",
       "       0.38579316, 0.87750055, 0.56459191, 0.1280783 , 0.1031813 ,\n",
       "       0.91169573, 0.14231518, 0.88773175, 0.12607941, 0.12971138,\n",
       "       0.90753802, 0.12635156, 0.90891637, 0.35988715, 0.30442411,\n",
       "       0.18966796, 0.15015204, 0.26822419, 0.65488934, 0.64585315,\n",
       "       0.65489619, 0.90711865, 0.56933465, 0.13014   , 0.86010063,\n",
       "       0.10126669, 0.13014   , 0.41850305])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
